{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 임베딩파일이 있는 상태에서, 기존 파일들은 제외하고 새 문서들만 임베딩하는 자동화 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing ChromaDB collection:\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Initialize the ChromaDB client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# Get the existing collection\n",
    "collection = client.get_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=embedding_functions.DefaultEmbeddingFunction()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to process and add new documents:\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import hashlib\n",
    "\n",
    "def add_new_documents(file_path):\n",
    "    # Load the new document\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Split the document into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Process and add each chunk\n",
    "    for split in splits:\n",
    "        # Generate a unique ID based on content\n",
    "        doc_id = hashlib.md5(split.page_content.encode()).hexdigest()\n",
    "        \n",
    "        # Check if the document already exists\n",
    "        if not collection.get(ids=[doc_id])['ids']:\n",
    "            # Add the new document chunk\n",
    "            collection.add(\n",
    "                documents=[split.page_content],\n",
    "                metadatas=[{\"source\": file_path}],\n",
    "                ids=[doc_id]\n",
    "            )\n",
    "            print(f\"Added new document chunk: {doc_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to add new documents:\n",
    "\n",
    "# Add a new document\n",
    "add_new_documents(\"path/to/new/document.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach allows you to:\n",
    "\n",
    "Connect to the existing ChromaDB collection.\n",
    "\n",
    "Load and process new documents.\n",
    "\n",
    "Split new documents into chunks for better retrieval.\n",
    "\n",
    "Generate unique IDs for each chunk to avoid duplicates.\n",
    "\n",
    "Add only new document chunks that don't already exist in the collection.\n",
    "\n",
    "By using this method, you can incrementally add new documents to your existing ChromaDB instance without reloading or recomputing embeddings for documents that are already in the database.\n",
    "\n",
    "Remember to adjust the chunk size and overlap in the RecursiveCharacterTextSplitter according to your specific needs.\n",
    "Also, make sure to use the same embedding function that was used for the initial documents to maintain consistency in your vector space.\n",
    "\n",
    "This approach allows you to dynamically expand your knowledge base while preserving the existing embeddings and documents in your ChromaDB instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref\n",
    "- https://github.com/run-llama/llama_index/issues/15082\n",
    "- https://how.wtf/how-to-use-chroma-db-step-by-step-guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
